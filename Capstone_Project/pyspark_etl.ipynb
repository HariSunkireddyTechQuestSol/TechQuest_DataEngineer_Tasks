{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qid5PPNAyNyS"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import sqlite3\n",
        "\n",
        "# CAPSTONE ETL PIPELINE\n",
        "# Extract  → Transform → Load using PySpark\n",
        "\n",
        "def etl_process(csv_file, db_file, table_name):\n",
        "\n",
        "    \"\"\"\n",
        "    Capstone ETL Function\n",
        "    ---------------------\n",
        "    Extracts employee data from a CSV file, transforms it using PySpark,\n",
        "    and loads the final dataset into a SQLite database.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # 1. SPARK SESSION INITIALIZATION\n",
        "\n",
        "    # SparkSession is the main entry point for PySpark\n",
        "    spark = SparkSession.builder \\\n",
        "        .appName(\"Week8_Capstone_ETL_Project\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    try:\n",
        "\n",
        "        # 2. EXTRACT\n",
        "\n",
        "        # Load CSV data into a Spark DataFrame\n",
        "        # inferSchema automatically detects column data types\n",
        "        df = spark.read.csv(csv_file, header=True, inferSchema=True)\n",
        "\n",
        "        print(\"=== Extracted Raw Data ===\")\n",
        "        df.show()\n",
        "\n",
        "\n",
        "        # 3. TRANSFORM\n",
        "\n",
        "        # Step 1: Remove records with missing values\n",
        "        # This improves data quality and reliability\n",
        "        cleaned_df = df.dropna()\n",
        "\n",
        "        print(\"=== After Removing Null Values ===\")\n",
        "        cleaned_df.show()\n",
        "\n",
        "        # Step 2: Rename columns for standard naming conventions\n",
        "        transformed_df = cleaned_df \\\n",
        "            .withColumnRenamed(\"Name\", \"Employee Name\") \\\n",
        "            .withColumnRenamed(\"Salary($)\", \"Salary\")\n",
        "\n",
        "        print(\"=== After Renaming Columns ===\")\n",
        "        transformed_df.show()\n",
        "\n",
        "        # Step 3: Drop unnecessary or sensitive columns\n",
        "        transformed_df = transformed_df.drop(\n",
        "            \"Email ID\", \"Joining Date\", \"Phone No\"\n",
        "        )\n",
        "\n",
        "        print(\"=== After Dropping Unnecessary Columns ===\")\n",
        "        transformed_df.show()\n",
        "\n",
        "        # Step 4: Add derived column using business logic\n",
        "        # Calculate 10% salary hike for each employee\n",
        "        transformed_df = transformed_df.withColumn(\n",
        "            \"Salary Hike\",\n",
        "            col(\"Salary\") * 0.10\n",
        "        )\n",
        "\n",
        "        print(\"=== After Adding Salary Hike Column ===\")\n",
        "        transformed_df.show()\n",
        "\n",
        "\n",
        "        # 4. LOAD\n",
        "\n",
        "        # Convert Spark DataFrame to Pandas DataFrame\n",
        "        # SQLite does not support direct Spark writes efficiently\n",
        "        final_df = transformed_df.toPandas()\n",
        "\n",
        "        # Connect to SQLite database\n",
        "        conn = sqlite3.connect(db_file)\n",
        "\n",
        "        # Load data into SQLite table\n",
        "        final_df.to_sql(\n",
        "            table_name,\n",
        "            conn,\n",
        "            if_exists=\"replace\",\n",
        "            index=False\n",
        "        )\n",
        "\n",
        "        conn.close()\n",
        "\n",
        "        print(\n",
        "            f\"Data successfully loaded into database '{db_file}' \"\n",
        "            f\"inside table '{table_name}'\"\n",
        "        )\n",
        "\n",
        "        return final_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Capstone ETL Pipeline Failed: {e}\")\n",
        "        raise\n",
        "\n",
        "    finally:\n",
        "\n",
        "        # 5. SPARK SESSION TERMINATION\n",
        "\n",
        "        # Always stop Spark session after job completion\n",
        "        spark.stop()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CAPSTONE PIPELINE EXECUTION\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    etl_process(\n",
        "        csv_file=\"EmployeeData copy.csv\",\n",
        "        db_file=\"EmployeeData.db\",\n",
        "        table_name=\"EmployeeData\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0miTL8KMyY_0",
        "outputId": "5f9b5a3f-b4ba-4102-8693-2eb8c65acc9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Extracted Raw Data ===\n",
            "+---+------+---------------+----------+---------+------------+--------------------+----------+\n",
            "|_c0|Emp ID|       FullName|      Dept|Salary($)|Joining Date|            Email ID|  Phone No|\n",
            "+---+------+---------------+----------+---------+------------+--------------------+----------+\n",
            "|  0|   101|   Alex Johnson|     Admin|  47508.0|  2017-01-27|alex.johnson@work...|9475287752|\n",
            "|  1|   102|    Liam Wilson|        IT|     NULL|  2024-08-12|                NULL|9744732697|\n",
            "|  2|   103|  Olivia Martin| Marketing|     NULL|  2021-02-08|olivia.martin@exa...|      NULL|\n",
            "|  3|   104|  Olivia Martin|        IT|  75115.0|  2016-06-10|                NULL|      NULL|\n",
            "|  4|   105|    Mason Young|     Admin|  83571.0|  2019-07-03|                NULL|9469220313|\n",
            "|  5|   106| Benjamin Adams|   Finance|     NULL|  2023-09-28|benjamin.adams@wo...|      NULL|\n",
            "|  6|   107|   Sophia Davis|        IT|  67812.0|  2022-05-15|                NULL|9242110844|\n",
            "|  7|   108|   Rajesh Kumar|     Sales|  73524.0|  2019-02-01|rajesh.kumar@comp...|9994378247|\n",
            "|  8|   109|   Amelia Scott| Marketing|  88624.0|  2018-08-23|amelia.scott@exam...|      NULL|\n",
            "|  9|   110|    Emily Brown|     Admin|  94815.0|  2021-12-04|                NULL|      NULL|\n",
            "| 10|   111|    Noah Walker|   Finance|  58519.0|  2019-09-13|noah.walker@compa...|9926731527|\n",
            "| 11|   112|  Isabella Hall|Operations|     NULL|  2020-01-05|                NULL|9726481992|\n",
            "| 12|   113|  Ava Rodriguez|     Sales|  47288.0|  2018-04-20|ava.rodriguez@wor...|9608253749|\n",
            "| 13|   114|    Jacob Allen|   Finance|  81023.0|  2015-09-12|jacob.allen@examp...|      NULL|\n",
            "| 14|   115|    Ethan Clark|        HR|     NULL|  2020-06-14|                NULL|9865710428|\n",
            "| 15|   116|       Mia King|        IT|  74826.0|  2023-05-19|mia.king@company.org|      NULL|\n",
            "| 16|   117|   Lucas Wright|Operations|     NULL|  2019-02-22|                NULL|9264185710|\n",
            "| 17|   118|     John Smith|     Admin|  58937.0|  2024-04-11|john.smith@workpl...|      NULL|\n",
            "| 18|   119|   Amelia Scott| Marketing|  85174.0|  2017-09-17|amelia.scott@work...|9224158799|\n",
            "| 19|   120|Charlotte Baker|     Sales|     NULL|  2016-03-06|                NULL|      NULL|\n",
            "+---+------+---------------+----------+---------+------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "=== After Removing Null Values ===\n",
            "+---+------+--------------+----------+---------+------------+--------------------+----------+\n",
            "|_c0|Emp ID|      FullName|      Dept|Salary($)|Joining Date|            Email ID|  Phone No|\n",
            "+---+------+--------------+----------+---------+------------+--------------------+----------+\n",
            "|  0|   101|  Alex Johnson|     Admin|  47508.0|  2017-01-27|alex.johnson@work...|9475287752|\n",
            "|  7|   108|  Rajesh Kumar|     Sales|  73524.0|  2019-02-01|rajesh.kumar@comp...|9994378247|\n",
            "| 10|   111|   Noah Walker|   Finance|  58519.0|  2019-09-13|noah.walker@compa...|9926731527|\n",
            "| 12|   113| Ava Rodriguez|     Sales|  47288.0|  2018-04-20|ava.rodriguez@wor...|9608253749|\n",
            "| 18|   119|  Amelia Scott| Marketing|  85174.0|  2017-09-17|amelia.scott@work...|9224158799|\n",
            "| 20|   121|Benjamin Adams|   Finance|  68974.0|  2020-07-15|benjamin.adams@co...|9671548392|\n",
            "| 22|   123|   Emily Brown|     Admin|  74185.0|  2016-11-21|emily.brown@examp...|9993267785|\n",
            "| 24|   125|     David Lee|        IT|  62509.0|  2015-07-17|david.lee@company...|9134776210|\n",
            "| 28|   129|    John Smith|Operations|  69314.0|  2024-01-18|john.smith@exampl...|9873305512|\n",
            "| 36|   137|      Mia King|   Finance|  70544.0|  2019-05-13|mia.king@example.com|9478102394|\n",
            "+---+------+--------------+----------+---------+------------+--------------------+----------+\n",
            "\n",
            "=== After Renaming Columns ===\n",
            "+---+------+--------------+----------+-------+------------+--------------------+----------+\n",
            "|_c0|Emp ID|      FullName|      Dept| Salary|Joining Date|            Email ID|  Phone No|\n",
            "+---+------+--------------+----------+-------+------------+--------------------+----------+\n",
            "|  0|   101|  Alex Johnson|     Admin|47508.0|  2017-01-27|alex.johnson@work...|9475287752|\n",
            "|  7|   108|  Rajesh Kumar|     Sales|73524.0|  2019-02-01|rajesh.kumar@comp...|9994378247|\n",
            "| 10|   111|   Noah Walker|   Finance|58519.0|  2019-09-13|noah.walker@compa...|9926731527|\n",
            "| 12|   113| Ava Rodriguez|     Sales|47288.0|  2018-04-20|ava.rodriguez@wor...|9608253749|\n",
            "| 18|   119|  Amelia Scott| Marketing|85174.0|  2017-09-17|amelia.scott@work...|9224158799|\n",
            "| 20|   121|Benjamin Adams|   Finance|68974.0|  2020-07-15|benjamin.adams@co...|9671548392|\n",
            "| 22|   123|   Emily Brown|     Admin|74185.0|  2016-11-21|emily.brown@examp...|9993267785|\n",
            "| 24|   125|     David Lee|        IT|62509.0|  2015-07-17|david.lee@company...|9134776210|\n",
            "| 28|   129|    John Smith|Operations|69314.0|  2024-01-18|john.smith@exampl...|9873305512|\n",
            "| 36|   137|      Mia King|   Finance|70544.0|  2019-05-13|mia.king@example.com|9478102394|\n",
            "+---+------+--------------+----------+-------+------------+--------------------+----------+\n",
            "\n",
            "=== After Dropping Unnecessary Columns ===\n",
            "+---+------+--------------+----------+-------+\n",
            "|_c0|Emp ID|      FullName|      Dept| Salary|\n",
            "+---+------+--------------+----------+-------+\n",
            "|  0|   101|  Alex Johnson|     Admin|47508.0|\n",
            "|  7|   108|  Rajesh Kumar|     Sales|73524.0|\n",
            "| 10|   111|   Noah Walker|   Finance|58519.0|\n",
            "| 12|   113| Ava Rodriguez|     Sales|47288.0|\n",
            "| 18|   119|  Amelia Scott| Marketing|85174.0|\n",
            "| 20|   121|Benjamin Adams|   Finance|68974.0|\n",
            "| 22|   123|   Emily Brown|     Admin|74185.0|\n",
            "| 24|   125|     David Lee|        IT|62509.0|\n",
            "| 28|   129|    John Smith|Operations|69314.0|\n",
            "| 36|   137|      Mia King|   Finance|70544.0|\n",
            "+---+------+--------------+----------+-------+\n",
            "\n",
            "=== After Adding Salary Hike Column ===\n",
            "+---+------+--------------+----------+-------+-----------------+\n",
            "|_c0|Emp ID|      FullName|      Dept| Salary|      Salary Hike|\n",
            "+---+------+--------------+----------+-------+-----------------+\n",
            "|  0|   101|  Alex Johnson|     Admin|47508.0|           4750.8|\n",
            "|  7|   108|  Rajesh Kumar|     Sales|73524.0|7352.400000000001|\n",
            "| 10|   111|   Noah Walker|   Finance|58519.0|5851.900000000001|\n",
            "| 12|   113| Ava Rodriguez|     Sales|47288.0|           4728.8|\n",
            "| 18|   119|  Amelia Scott| Marketing|85174.0|           8517.4|\n",
            "| 20|   121|Benjamin Adams|   Finance|68974.0|6897.400000000001|\n",
            "| 22|   123|   Emily Brown|     Admin|74185.0|           7418.5|\n",
            "| 24|   125|     David Lee|        IT|62509.0|6250.900000000001|\n",
            "| 28|   129|    John Smith|Operations|69314.0|6931.400000000001|\n",
            "| 36|   137|      Mia King|   Finance|70544.0|7054.400000000001|\n",
            "+---+------+--------------+----------+-------+-----------------+\n",
            "\n",
            "Data successfully loaded into database 'EmployeeData.db' inside table 'EmployeeData'\n"
          ]
        }
      ]
    }
  ]
}