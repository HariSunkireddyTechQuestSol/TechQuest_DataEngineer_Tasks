# Data Engineering Foundations – 8 Week Program

## Repository Overview

This repository contains my complete coursework for an **8-week Data Engineering training program**.
The program is designed to build strong foundations in **Python programming, data processing, SQL, ETL pipelines, APIs, cloud concepts, PySpark, and capstone project implementation**.

Each week focuses on a specific set of skills and includes:

* Daily hands-on coding tasks
* Mini projects for practical application
* Weekly assessments to validate learning
* A final capstone project demonstrating end-to-end data engineering concepts

---

## Program Objectives

The primary objectives of this program are to:

* Develop strong Python programming fundamentals
* Understand data manipulation using Pandas and NumPy
* Gain hands-on experience with SQL and databases
* Design and implement ETL pipelines
* Work with APIs and JSON data
* Understand cloud storage concepts
* Learn PySpark for large-scale data processing
* Build a real-world capstone ETL project

---

## Repository Structure

```
Data_Engineering_8_Weeks/
│
├── Week1/     # Python & Git Foundations
├── Week2/     # NumPy, Pandas, and Data Cleaning
├── Week3/     # SQL Basics & Python-SQL Integration
├── Week4/     # ETL Concepts and Implementation
├── Week5/     # APIs and JSON Data Processing
├── Week6/     # Cloud Data Fundamentals (AWS S3 Simulation)
├── Week7/     # PySpark Basics and Spark ETL
├── Week8/     # Capstone & Final ETL Project
└── README.md  # Program documentation
```

---

## Weekly Breakdown

---

## Week 1 – Python & Git Foundations

**Focus:** Core Python programming and version control

### Topics Covered

* Python syntax, variables, and data types
* User input handling
* Conditional statements and loops
* Functions and error handling
* File read/write operations
* Git and GitHub workflow

### Mini Project

* Collect user input and store data in a CSV file
* Read and display formatted reports from the file

---

## Week 2 – NumPy, Pandas, and Data Cleaning

**Focus:** Data manipulation and cleaning

### Topics Covered

* NumPy arrays and operations
* Pandas Series and DataFrames
* Reading CSV files
* Handling missing data
* Data filtering, sorting, and grouping

### Mini Project

* Load employee data
* Clean missing values
* Rename columns and export cleaned dataset

---

## Week 3 – SQL Basics & Python-SQL Integration

**Focus:** Relational databases and SQL operations

### Topics Covered

* SQL CRUD operations
* SQLite database creation
* Table joins and conditional queries
* Python integration with SQLite
* Executing update and delete operations

### Mini Project

* Employee database creation
* Insert, query, update, and join employee records

---

## Week 4 – Data Transformation and ETL Basics

**Focus:** ETL pipeline fundamentals

### Topics Covered

* ETL concepts (Extract, Transform, Load)
* Reading data from CSV and JSON
* Data transformation logic
* Loading data into databases
* ETL automation using Python functions

### Mini Project

* Build an end-to-end ETL pipeline:
  CSV → Clean & Transform → SQLite Database

---

## Week 5 – APIs and JSON Data

**Focus:** External data ingestion

### Topics Covered

* JSON file handling
* API requests using Python
* Parsing API responses
* Converting JSON to DataFrames
* Storing API data for analysis

### Mini Project

* Fetch live API data
* Clean and transform response
* Store results in database

---

## Week 6 – AWS & Cloud Data Basics

**Focus:** Cloud storage concepts (simulated)

### Topics Covered

* AWS S3 concepts
* Simulated cloud storage using local directories
* Uploading and reading data from cloud-like storage
* Performing ETL on cloud-based data

### Mini Project

* Simulated cloud storage system
* ETL pipeline using cloud-stored files
* Report generation

---

## Week 7 – PySpark Basics

**Focus:** Distributed data processing

### Topics Covered

* SparkSession creation
* Spark DataFrame operations
* Filtering and transformations
* Aggregations and groupBy operations
* Saving processed Spark data

### Mini Project

* Spark-based ETL job:
  Read → Transform → Save processed data

---

## Week 8 – Capstone & Final Project

**Focus:** End-to-end data engineering implementation

### Capstone Highlights

* Dataset selection and ETL planning
* Data extraction from CSV or API
* Data transformation and business logic
* Database loading (SQLite/PostgreSQL)
* Fully automated ETL pipeline

### Capstone Outcome

* Production-style ETL system
* Clean, modular, and reusable code
* Strong foundation for real-world data engineering workflows

---

## Skills Gained

* Python Programming
* Data Cleaning and Transformation
* SQL and Database Design
* ETL Pipeline Development
* API Integration
* Cloud Data Concepts
* PySpark Fundamentals
* End-to-End Data Engineering Design

---

## Conclusion

This 8-week program provided comprehensive, hands-on exposure to core data engineering concepts.
The repository reflects progressive learning from Python basics to a full-scale capstone ETL project, demonstrating readiness for entry-level to intermediate data engineering roles.

---

## Author

**Hari Sunkireddy**
Data Engineering Trainee
GitHub: https://github.com/HariSunkireddyTechQuestSol/TechQuest_DataEngineer_Tasks

---

